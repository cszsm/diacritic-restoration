{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "vowel_table = {\"a\" : [\"á\"], \"e\" : [\"é\"], \"i\" : [\"í\"], \"o\" : [\"ó\", \"ö\", \"ő\"], \"u\" : [\"ú\", \"ü\", \"ű\"]}\n",
    "vectorizer = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ispunct(c):\n",
    "    punctuations = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    for char in punctuations:\n",
    "        if (c == char):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def isalpha(c):\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    for char in alphabet:\n",
    "        if (c == char):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# reduces the number of different characters to 30\n",
    "def normalize_character(c):\n",
    "    if (c.isspace()):\n",
    "        return ' '\n",
    "    if (c.isdigit()):\n",
    "        return '0'\n",
    "    if (ispunct(c)):\n",
    "        return '_'\n",
    "    if (isalpha(c)):\n",
    "        return c\n",
    "    return '*'\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    normalized = \"\"\n",
    "    for c in text:\n",
    "        normalized += normalize_character(c)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deaccentize(text):\n",
    "    text = text.replace(\"á\", \"a\")\n",
    "    text = text.replace(\"é\", \"e\")\n",
    "    text = text.replace(\"í\", \"i\")\n",
    "    text = text.replace(\"ó\", \"o\")\n",
    "    text = text.replace(\"ö\", \"o\")\n",
    "    text = text.replace(\"ő\", \"o\")\n",
    "    text = text.replace(\"ú\", \"u\")\n",
    "    text = text.replace(\"ü\", \"u\")\n",
    "    text = text.replace(\"ű\", \"u\")\n",
    "\n",
    "    return text\n",
    "\n",
    "def create_row(window, window_size):\n",
    "    row = {}\n",
    "\n",
    "    for i in range(-window_size, window_size + 1):\n",
    "        row[i] = normalize_character(deaccentize(window.popleft()))\n",
    "\n",
    "    del row[0]\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def prepare_text(text, window_size, vowel):\n",
    "    x_e = []\n",
    "    y_e = []\n",
    "    lower_text = text.lower()\n",
    "\n",
    "    window = deque((), window_size * 2 + 1)\n",
    "    for i in range(window.maxlen):\n",
    "        window.append(\"_\")\n",
    "        lower_text += \"_\"\n",
    "\n",
    "    for character in lower_text:\n",
    "        window.append(character)\n",
    "        if window[window_size] == vowel:\n",
    "            x_e.append(create_row(window.copy(), window_size))\n",
    "            y_e.append([1, 0])\n",
    "        if window[window_size] in vowel_table[vowel]:\n",
    "            x_e.append(create_row(window.copy(), window_size))\n",
    "            y_e.append([0, 1])\n",
    "\n",
    "    return x_e, y_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generates template windows for the alphabet\n",
    "def generate_windows(window_size):\n",
    "    windows = []\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz 0_*\"\n",
    "    alphabet_size = len(alphabet)\n",
    "\n",
    "    for i in range(alphabet_size):\n",
    "        new_window = {}\n",
    "\n",
    "        end_of_slice = i + window_size * 2\n",
    "        if end_of_slice <= alphabet_size:\n",
    "            alphabet_slice = alphabet[i:end_of_slice]\n",
    "        else:\n",
    "            alphabet_slice = alphabet[i:alphabet_size]\n",
    "            alphabet_slice += alphabet[0:end_of_slice - alphabet_size]\n",
    "\n",
    "        for j in range(window_size):\n",
    "            new_window[-1 * (j + 1)] = alphabet_slice[window_size - 1 - j]\n",
    "            new_window[j + 1] = alphabet_slice[window_size + j]\n",
    "\n",
    "        windows.append(new_window)\n",
    "\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 240\n",
    "output_size = 2\n",
    "\n",
    "n_input = tf.placeholder(tf.float32, [None, input_size])\n",
    "n_output = tf.placeholder(tf.float32, [None, output_size])\n",
    "\n",
    "hidden_neurons = 10\n",
    "\n",
    "b_hidden = tf.Variable(tf.random_normal([hidden_neurons]))\n",
    "W_hidden = tf.Variable(tf.random_normal([input_size, hidden_neurons]))\n",
    "hidden = tf.sigmoid(tf.matmul(n_input, W_hidden) + b_hidden)\n",
    "\n",
    "W_output = tf.Variable(tf.random_normal([hidden_neurons, output_size]))\n",
    "output = tf.sigmoid(tf.matmul(hidden, W_output))\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(n_output - output))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.fit(generate_windows(4))\n",
    "\n",
    "train_data = \"A politika és az erkölcs kapcsolatáról régebben lezárt vita foglalkozott az erkölcs és a törvények kapcsolatával is.\"\n",
    "tmp_x, train_y = prepare_text(train_data, 4, \"e\")\n",
    "train_x = vectorizer.transform(tmp_x).toarray()\n",
    "\n",
    "test_data = \"Zsarnoki törvény és erkölcsi zsarnokság egyaránt nyomasztó.\"\n",
    "tmp_x, test_y = prepare_text(test_data, 4, \"e\")\n",
    "test_x = vectorizer.transform(tmp_x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "step:   0\n",
      "loss: 0.38514241576194763\n",
      "\n",
      "step: 100\n",
      "loss: 0.0806296318769455\n",
      "\n",
      "step: 200\n",
      "loss: 0.02782360091805458\n",
      "\n",
      "step: 300\n",
      "loss: 0.01437755860388279\n",
      "\n",
      "step: 400\n",
      "loss: 0.009060019627213478\n",
      "\n",
      "step: 500\n",
      "loss: 0.006361192557960749\n",
      "\n",
      "step: 600\n",
      "loss: 0.004781566560268402\n",
      "\n",
      "step: 700\n",
      "loss: 0.0037700801622122526\n",
      "\n",
      "step: 800\n",
      "loss: 0.0030800143722444773\n",
      "\n",
      "step: 900\n",
      "loss: 0.002585839480161667\n",
      "\n",
      "step: 1000\n",
      "loss: 0.002217965666204691\n",
      "\n",
      "step: 1100\n",
      "loss: 0.001935320207849145\n",
      "\n",
      "step: 1200\n",
      "loss: 0.0017124030273407698\n",
      "\n",
      "step: 1300\n",
      "loss: 0.0015327080618590117\n",
      "\n",
      "step: 1400\n",
      "loss: 0.0013851572293788195\n",
      "\n",
      "step: 1500\n",
      "loss: 0.001262078178115189\n",
      "\n",
      "step: 1600\n",
      "loss: 0.0011580116115510464\n",
      "\n",
      "step: 1700\n",
      "loss: 0.0010689758928492665\n",
      "\n",
      "step: 1800\n",
      "loss: 0.0009920155862346292\n",
      "\n",
      "step: 1900\n",
      "loss: 0.0009248846909031272\n",
      "\n",
      "step: 2000\n",
      "loss: 0.0008658539736643434\n",
      "\n",
      "step: 2100\n",
      "loss: 0.0008135723765008152\n",
      "\n",
      "step: 2200\n",
      "loss: 0.0007669708575122058\n",
      "\n",
      "step: 2300\n",
      "loss: 0.0007251876522786915\n",
      "\n",
      "step: 2400\n",
      "loss: 0.0006875263643451035\n",
      "\n",
      "step: 2500\n",
      "loss: 0.0006534178974106908\n",
      "\n",
      "step: 2600\n",
      "loss: 0.0006223911186680198\n",
      "\n",
      "step: 2700\n",
      "loss: 0.0005940546980127692\n",
      "\n",
      "step: 2800\n",
      "loss: 0.0005680790054611862\n",
      "\n",
      "step: 2900\n",
      "loss: 0.0005441859248094261\n",
      "\n",
      "step: 3000\n",
      "loss: 0.0005221381434239447\n",
      "\n",
      "step: 3100\n",
      "loss: 0.0005017338553443551\n",
      "\n",
      "step: 3200\n",
      "loss: 0.0004827988741453737\n",
      "\n",
      "step: 3300\n",
      "loss: 0.0004651820636354387\n",
      "\n",
      "step: 3400\n",
      "loss: 0.0004487538826651871\n",
      "\n",
      "step: 3500\n",
      "loss: 0.0004333987017162144\n",
      "\n",
      "step: 3600\n",
      "loss: 0.0004190162871964276\n",
      "\n",
      "step: 3700\n",
      "loss: 0.0004055193276144564\n",
      "\n",
      "step: 3800\n",
      "loss: 0.00039282915531657636\n",
      "\n",
      "step: 3900\n",
      "loss: 0.0003808767651207745\n",
      "\n",
      "step: 4000\n",
      "loss: 0.0003696006315294653\n",
      "\n",
      "step: 4100\n",
      "loss: 0.00035894563188776374\n",
      "\n",
      "step: 4200\n",
      "loss: 0.0003488627844490111\n",
      "\n",
      "step: 4300\n",
      "loss: 0.00033930776407942176\n",
      "\n",
      "step: 4400\n",
      "loss: 0.0003302405821159482\n",
      "\n",
      "step: 4500\n",
      "loss: 0.00032162552815862\n",
      "\n",
      "step: 4600\n",
      "loss: 0.0003134302678517997\n",
      "\n",
      "step: 4700\n",
      "loss: 0.00030562427127733827\n",
      "\n",
      "step: 4800\n",
      "loss: 0.00029818221810273826\n",
      "\n",
      "step: 4900\n",
      "loss: 0.0002910798357333988\n",
      "\n",
      "[[ 0.1515653   0.9339844 ]\n",
      " [ 0.26140243  0.69812357]\n",
      " [ 0.99356407  0.00808994]\n",
      " [ 0.60091794  0.67504454]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(5000):\n",
    "    cvalues = sess.run([train, cost, W_hidden, b_hidden, W_output], feed_dict={n_input: train_x, n_output: train_y})\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"\")\n",
    "        print(\"step: {:>3}\".format(i))\n",
    "        print(\"loss: {}\".format(cvalues[1]))\n",
    "\n",
    "print(\"\")\n",
    "print(sess.run(output, feed_dict={n_input: test_x}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
