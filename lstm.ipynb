{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vowel_table = {\"a\" : [\"á\"], \"e\" : [\"é\"], \"i\" : [\"í\"], \"o\" : [\"ó\", \"ö\", \"ő\"], \"u\" : [\"ú\", \"ü\", \"ű\"]}\n",
    "vectorizer = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def deaccentize(text):\n",
    "    text = text.replace(\"á\", \"a\")\n",
    "    text = text.replace(\"é\", \"e\")\n",
    "    text = text.replace(\"í\", \"i\")\n",
    "    text = text.replace(\"ó\", \"o\")\n",
    "    text = text.replace(\"ö\", \"o\")\n",
    "    text = text.replace(\"ő\", \"o\")\n",
    "    text = text.replace(\"ú\", \"u\")\n",
    "    text = text.replace(\"ü\", \"u\")\n",
    "    text = text.replace(\"ű\", \"u\")\n",
    "\n",
    "    return text\n",
    "\n",
    "def ispunct(c):\n",
    "    punctuations = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    for char in punctuations:\n",
    "        if (c == char):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def isalpha(c):\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    for char in alphabet:\n",
    "        if (c == char):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# reduces the number of different characters to 30\n",
    "def normalize_character(c):\n",
    "    if (c.isspace()):\n",
    "        return ' '\n",
    "    if (c.isdigit()):\n",
    "        return '0'\n",
    "    if (ispunct(c)):\n",
    "        return '_'\n",
    "    if (isalpha(c)):\n",
    "        return c\n",
    "    return '*'\n",
    "\n",
    "# generates template windows for the alphabet\n",
    "def generate_windows(window_size):\n",
    "    windows = []\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz 0_*\"\n",
    "    alphabet_size = len(alphabet)\n",
    "\n",
    "    for i in range(alphabet_size):\n",
    "        new_window = {}\n",
    "\n",
    "        end_of_slice = i + window_size * 2\n",
    "        # adding the center of the window\n",
    "        end_of_slice += 1\n",
    "        if end_of_slice <= alphabet_size:\n",
    "            alphabet_slice = alphabet[i:end_of_slice]\n",
    "        else:\n",
    "            alphabet_slice = alphabet[i:alphabet_size]\n",
    "            alphabet_slice += alphabet[0:end_of_slice - alphabet_size]\n",
    "\n",
    "        new_window[0] = alphabet_slice[window_size]\n",
    "        for j in range(window_size):\n",
    "            new_window[-1 * (j + 1)] = alphabet_slice[window_size - 1 - j]\n",
    "            new_window[j + 1] = alphabet_slice[window_size + j + 1] # ...+ 1... \n",
    "\n",
    "        windows.append(new_window)\n",
    "\n",
    "    return windows\n",
    "\n",
    "vectorizer.fit(generate_windows(1))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_corpus(count):\n",
    "    corpus = open(\"corpus\")\n",
    "    words = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        next(corpus)\n",
    "        \n",
    "    for line in corpus:\n",
    "        splits = line.split()\n",
    "        if splits != []:\n",
    "            words.append(splits[0])\n",
    "            if count < 0:\n",
    "                break\n",
    "            count -= 1\n",
    "        \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "onehot_enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "def fit_encoders():\n",
    "    windows = []\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz 0_*\"\n",
    "    alphabet_list = list(alphabet)\n",
    "#     print(alphabet_list)\n",
    "    label_enc.fit(alphabet_list)\n",
    "    label_list = label_enc.transform(alphabet_list)\n",
    "    onehot_enc.fit(label_list.reshape(-1, 1))\n",
    "    \n",
    "def transform(character):\n",
    "    character_label = label_enc.transform([character])\n",
    "    return onehot_enc.transform(character_label[0])[0]\n",
    "\n",
    "def transform_list(character_list):\n",
    "    transformed_list = []\n",
    "    \n",
    "    for character in character_list:\n",
    "        transformed_list.append(transform(character))\n",
    "    \n",
    "    return transformed_list\n",
    "\n",
    "fit_encoders()\n",
    "\n",
    "def encode_window(window):\n",
    "    encoded_window = []\n",
    "    \n",
    "    for element in window:\n",
    "        transformed_element = [transform(element)]\n",
    "        encoded_window.append(transformed_element)\n",
    "        \n",
    "    return encoded_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_accent(vowel):\n",
    "    if vowel in \"aei\":\n",
    "        return [1, 0]\n",
    "    if vowel in \"áéí\":\n",
    "        return [0, 1]\n",
    "    if vowel in \"ou\":\n",
    "        return [1, 0, 0, 0]\n",
    "    if vowel in \"óú\":\n",
    "        return [0, 1, 0, 0]\n",
    "    if vowel in \"öü\":\n",
    "        return [0, 0, 1, 0]\n",
    "    if vowel in \"őű\":\n",
    "        return [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 100000\n",
    "words = read_corpus(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deaccentize(text):\n",
    "    text = text.replace(\"á\", \"a\")\n",
    "    text = text.replace(\"é\", \"e\")\n",
    "    text = text.replace(\"í\", \"i\")\n",
    "    text = text.replace(\"ó\", \"o\")\n",
    "    text = text.replace(\"ö\", \"o\")\n",
    "    text = text.replace(\"ő\", \"o\")\n",
    "    text = text.replace(\"ú\", \"u\")\n",
    "    text = text.replace(\"ü\", \"u\")\n",
    "    text = text.replace(\"ű\", \"u\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ispunct(c):\n",
    "    punctuations = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    for char in punctuations:\n",
    "        if (c == char):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def isalpha(c):\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    for char in alphabet:\n",
    "        if (c == char):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# reduces the number of different characters to 30\n",
    "def normalize_character(c):\n",
    "    if (c.isspace()):\n",
    "        return ' '\n",
    "    if (c.isdigit()):\n",
    "        return '0'\n",
    "    if (ispunct(c)):\n",
    "        return '_'\n",
    "    if (isalpha(c)):\n",
    "        return c\n",
    "    return '*'\n",
    "\n",
    "def normalize_list(character_list):\n",
    "    normalized_list = []\n",
    "    \n",
    "    for c in character_list:\n",
    "        normalized_list.append(normalize_character(deaccentize(c)))\n",
    "    \n",
    "    return normalized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pad_word(word, window_size):\n",
    "    if window_size > 0:\n",
    "        return '_' + pad_word(word, window_size - 1) + '_'\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def make_windows_from_word(word, window_size, vowel):\n",
    "    windows = []\n",
    "    accents = []\n",
    "    \n",
    "    sliding_window = deque((), window_size * 2 + 1)\n",
    "    \n",
    "    \n",
    "    for character in word[:sliding_window.maxlen - 1]:\n",
    "        sliding_window.append(character)\n",
    "    \n",
    "    for character in word[sliding_window.maxlen - 1:]:\n",
    "        sliding_window.append(character)\n",
    "        \n",
    "        if (sliding_window[window_size] == vowel) or (sliding_window[window_size] in vowel_table[vowel]):\n",
    "            normalized_list = normalize_list(list(sliding_window))\n",
    "            transformed_list = transform_list(normalized_list)\n",
    "            transformed_accents = sliding_window[window_size]\n",
    "            \n",
    "            windows.append(transformed_list)\n",
    "            accents.append(transform_accent(transformed_accents))\n",
    "    \n",
    "    return windows, accents\n",
    "    \n",
    "def make_windows_from_text(text, window_size, vowel):\n",
    "    windows = []\n",
    "    accents = []\n",
    "    \n",
    "    for word in text:\n",
    "        padded_word = pad_word(word, window_size)\n",
    "        \n",
    "        new_windows, new_accents = make_windows_from_word(padded_word, window_size, vowel)\n",
    "#         windows.append(new_windows)\n",
    "#         accents.append(new_accents)\n",
    "        windows += new_windows\n",
    "        accents += new_accents\n",
    "        \n",
    "    return windows, accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "w = words[:10000]\n",
    "x, y = make_windows_from_text(w, 1, 'a')\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(2, return_sequences=False, input_shape=(3, 30)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "\n",
    "model.compile(loss='mean_squared_logarithmic_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1300/1300 [==============================] - 0s - loss: 0.2191 - acc: 0.5000     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/10\n",
      "1300/1300 [==============================] - 0s - loss: 0.2062 - acc: 0.5562     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/10\n",
      "1300/1300 [==============================] - 0s - loss: 0.1963 - acc: 0.5508     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/10\n",
      "1300/1300 [==============================] - 0s - loss: 0.1864 - acc: 0.5269     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/10\n",
      "1300/1300 [==============================] - 0s - loss: 0.1787 - acc: 0.5485     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/10\n",
      "1300/1300 [==============================] - 0s - loss: 0.1718 - acc: 0.5438     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/10\n",
      "1300/1300 [==============================] - 0s - loss: 0.1648 - acc: 0.5446     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/10\n",
      "1300/1300 [==============================] - 0s - loss: 0.1573 - acc: 0.5785     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/10\n",
      "1300/1300 [==============================] - 0s - loss: 0.1527 - acc: 0.5615     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/10\n",
      "1300/1300 [==============================] - 0s - loss: 0.1477 - acc: 0.5754     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe679e37c50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4416/5202 [========================>.....] - ETA: 0s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13453705814516301, 0.67147251059577262]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22496337  0.15532254]\n",
      " [ 0.22496337  0.15532254]\n",
      " [ 0.22496337  0.15532254]]\n",
      "[[ 0.22496337  0.15532254]\n",
      " [ 0.22496337  0.15532254]]\n"
     ]
    }
   ],
   "source": [
    "x, y = make_windows_from_text('áradat', 1, 'a')\n",
    "print(model.predict(x))\n",
    "\n",
    "x, y = make_windows_from_text('állat', 1, 'a')\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
